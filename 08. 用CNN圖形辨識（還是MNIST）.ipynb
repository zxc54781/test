{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yann LeCun 被譽為 Deep Learning 的三巨頭之一。他的 CNN (Convolutional Neural Networks) 是讓 Neural Network 重新受到重視的主因之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-1 初始準備\n",
    "\n",
    "基本上和之前是一樣的, 我們就不再說明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-2 讀入 MNIST 數據庫\n",
    "\n",
    "### 由 Keras 讀入 MNIST\n",
    "\n",
    "基本上和我們上次一樣, 這次因為 Keras 已偷偷把數據庫存在你的電腦, 所以會快很多!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸入格式整理\n",
    "\n",
    "如果你還記得, 我們每筆輸入資料都是 28x28 的陣列, CNN 其實就是吃「圖」的, 所以基本上不用像之前把每筆資料拉平。「但。是。」平常的圖都有 R, G, B 三個 channels, 每個 channel 都是一個矩陣, 也就是一張圖可能是三個矩陣! 我們是灰階, 也就是只有一個 channel。但這件事也要明確的告訴 Keras。\n",
    "\n",
    "換句話說, 我們的輸入每筆資料型式要從 (28, 28) 換成 (28, 28, 1)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1234].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 要的 (28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認一下..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(60000,28,28,1)\n",
    "x_test=x_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原來 28x28 矩陣..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1234].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=x_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸出格式整理\n",
    "\n",
    "和上次一樣, 我們用標準 1-hot 方式處理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train,10)\n",
    "y_test = np_utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm=(x_train - x_train.min())/(x_train.max()-x_train.min())\n",
    "x_test_norm=(x_test - x_test.min())/(x_test.max()-x_test.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-3 打造你的 CNN\n",
    "\n",
    "### 決定神經網路架構、讀入相關套件\n",
    "\n",
    "CNN 我們一樣要決定用幾層的 CNN, 然後是不是每次都要做 max-pooling。再來就是拉平、送入標準神經網路 (再度要決定幾層、幾個神經元)。\n",
    "\n",
    "* 做 <span style=\"color:red;\">3</span> 次 convolution, 每次都接 max-pooling\n",
    "* filter 大小都是 <span style=\"color:red;\">3x3</span>, max-pooling 都用 <span style=\"color:red;\">2x2</span> 為一小區塊\n",
    "\n",
    "CNN 一個小技巧是每層的 filters 數目是越來越多。做完 convolution 之後, 我們要拉平、再送入一個標準的神經網路。這個神經網路設計是這樣:\n",
    "\n",
    "* 只有 <span style=\"color:red;\">1</span> 個隱藏層, 使用 <span style=\"color:red;\">200</span> 個神經元。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation , Flatten#(拉平)\n",
    "from keras.layers import Conv2D ,MaxPool2D\n",
    "from keras.optimizers import SGD,Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建構我們的神經網路\n",
    "\n",
    "一開始一樣是打開個空白的神經網路。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一個隱藏層一樣要告訴 Keras 我們輸入長什麼樣子。`padding` 設成 `same` 是每個 filter 會輸出原來 28x28 一樣大小的矩陣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(8,(5,5),padding='same',input_shape=(28,28,1))) #第一層 4個 filter size 5*5 \n",
    "model.add(Activation('elu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max-Pooling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二次 Convolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16,(5,5),padding='same')) #第二層 8個 filter size 5*5 \n",
    "model.add(Activation('selu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再 Max-Pooling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三次 Convolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,(5,5),padding='same')) #第二層 8個 filter size 5*5 \n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max-Pooling 最終回。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然後我們要送進一般的神經網路了。記得這是要拉平的, 還在 Keras 會幫我們做!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(9))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "輸出和上次一樣!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0xb279f8eb8>>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 組裝\n",
    "\n",
    "和之前比較不一樣的是我們還要做 `compile` 才正式把我們的神經網路建好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss=\"categorical_crossentropy\",\n",
    "#              optimizer=Adadelta(),\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "                    optimizer=SGD(lr=0.01),\n",
    "                      metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢視我們的神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 8)         208       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 16)        3216      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 32)          12832     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 2601      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                100       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 18,957\n",
      "Trainable params: 18,957\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-4 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 33s 553us/step - loss: 0.0825 - acc: 0.2464\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 33s 551us/step - loss: 0.0733 - acc: 0.3072\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 33s 552us/step - loss: 0.0723 - acc: 0.3116\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 32s 540us/step - loss: 0.0718 - acc: 0.3154\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 33s 554us/step - loss: 0.0699 - acc: 0.3121\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 39s 650us/step - loss: 0.0637 - acc: 0.3251\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 37s 609us/step - loss: 0.0559 - acc: 0.4416\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 35s 582us/step - loss: 0.0504 - acc: 0.5658\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 36s 606us/step - loss: 0.0475 - acc: 0.5987\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 38s 636us/step - loss: 0.0434 - acc: 0.6444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x108510978>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=75,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 8-5 結果測試"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 儲存結果\n",
    "\n",
    "結果看來還不差, 所以我們把結果存起來。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 欣賞一下成果\n",
    "\n",
    "我們用另一個方式: 每次選 5 個顯示, 看是不是有正確辨識。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD,Adam,Nadam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小結論\n",
    "\n",
    "我們到此, 基本上是「亂做」的神經網路。有些同學在不斷試驗的過程中, 可能會發現有時會出現很糟糕的結果。因此, 接下來我們要介紹怎麼樣用些簡單的手法, 能讓學習效果比較穩定, 而且有可能可以增加學習效率。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
